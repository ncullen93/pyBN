{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factor Operations with pyBN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is probably rare that a user wants to directly manipulate factors unless they are developing a new algorithm, but it's still important to see how factor operations are done in pyBN. Moreover, the ease-of-use and transparency of pyBN's factor operations mean it can be a great teaching/learning tool!\n",
    "\n",
    "In this tutorial, I will go over the main operations you can do with factors. First, let's start with actually creating a factor. So, we will read in a Bayesian Network from one of the included networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyBN import *\n",
    "bn = read_bn('data/cmu.bn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Burglary', 'Earthquake', 'Alarm', 'JohnCalls', 'MaryCalls']\n",
      "[['Burglary', 'Alarm'], ['Earthquake', 'Alarm'], ['Alarm', 'JohnCalls'], ['Alarm', 'MaryCalls']]\n"
     ]
    }
   ],
   "source": [
    "print bn.V\n",
    "print bn.E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have a Bayesian network with 5 nodes and some edges between them. Let's create a factor now. This is easy in pyBN - just pass in the BayesNet object and the name of the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alarm_factor = Factor(bn,'Alarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a factor, we can explore its properties. Every factor in pyBN has the following attributes:\n",
    "\n",
    "    *self.bn* : a BayesNet object\n",
    "\n",
    "    *self.var* : a string\n",
    "        The random variable to which this Factor belongs\n",
    "    \n",
    "    *self.scope* : a list\n",
    "        The RV, and its parents (the RVs involved in the\n",
    "        conditional probability table)\n",
    "    \n",
    "    *self.card* : a dictionary, where\n",
    "        key = an RV in self.scope, and\n",
    "        val = integer cardinality of the key (i.e. how\n",
    "            many possible values it has)\n",
    "    \n",
    "    *self.stride* : a dictionary, where\n",
    "        key = an RV in self.scope, and\n",
    "        val = integer stride (i.e. how many rows in the \n",
    "            CPT until the NEXT value of RV is reached)\n",
    "    \n",
    "    *self.cpt* : a nested numpy array\n",
    "        The probability values for self.var conditioned\n",
    "        on its parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyBN.classes.bayesnet.BayesNet object at 0x10c73ced0>\n",
      "Alarm\n",
      "['Alarm', 'Burglary', 'Earthquake']\n",
      "{'Burglary': 2, 'Alarm': 2, 'Earthquake': 2}\n",
      "{'Burglary': 2, 'Alarm': 1, 'Earthquake': 4}\n",
      "[ 0.999  0.001  0.71   0.29   0.06   0.94   0.05   0.95 ]\n"
     ]
    }
   ],
   "source": [
    "print alarm_factor.bn\n",
    "print alarm_factor.var\n",
    "print alarm_factor.scope\n",
    "print alarm_factor.card\n",
    "print alarm_factor.stride\n",
    "print alarm_factor.cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with those properties, there are a great number of methods (functions) at hand:\n",
    "\n",
    "    *multiply_factor*\n",
    "        Multiply two factors together. The factor\n",
    "        multiplication algorithm used here is adapted\n",
    "        from Koller and Friedman (PGMs) textbook.\n",
    "\n",
    "    *sumover_var* :\n",
    "        Sum over one *rv* by keeping it constant. Thus, you \n",
    "        end up with a 1-D factor whose scope is ONLY *rv*\n",
    "        and whose length = cardinality of rv. \n",
    "\n",
    "    *sumout_var_list* :\n",
    "        Remove a collection of rv's from the factor\n",
    "        by summing out (i.e. calling sumout_var) over\n",
    "        each rv.\n",
    "\n",
    "    *sumout_var* :\n",
    "        Remove passed-in *rv* from the factor by summing\n",
    "        over everything else.\n",
    "\n",
    "    *maxout_var* :\n",
    "        Remove *rv* from the factor by taking the maximum value \n",
    "        of all rv instantiations over everyting else.\n",
    "\n",
    "    *reduce_factor_by_list* :\n",
    "        Reduce the factor by numerous sets of\n",
    "        [rv,val]\n",
    "\n",
    "    *reduce_factor* :\n",
    "        Condition the factor by eliminating any sets of\n",
    "        values that don't align with a given [rv, val]\n",
    "\n",
    "    *to_log* :\n",
    "        Convert probabilities to log space from\n",
    "        normal space.\n",
    "\n",
    "    *from_log* :\n",
    "        Convert probabilities from log space to\n",
    "        normal space.\n",
    "\n",
    "    *normalize* :\n",
    "        Make relevant collections of probabilities sum to one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a look at Factor Multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.998  0.001  0.001  0.     0.06   0.939  0.     0.001]\n",
      "\n",
      "[ 0.998  0.001  0.001  0.     0.06   0.939  0.     0.001]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "f1 = Factor(bn,'Alarm')\n",
    "f2 = Factor(bn,'Burglary')\n",
    "f1.multiply_factor(f2)\n",
    "\n",
    "f3 = Factor(bn,'Burglary')\n",
    "f4 = Factor(bn,'Alarm')\n",
    "f3.multiply_factor(f4)\n",
    "\n",
    "print np.round(f1.cpt,3)\n",
    "print '\\n',np.round(f3.cpt,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a look at \"sumover_var\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.999  0.001  0.71   0.29   0.06   0.94   0.05   0.95 ]\n",
      "['Alarm', 'Burglary', 'Earthquake']\n",
      "{'Burglary': 2, 'Alarm': 1, 'Earthquake': 4}\n",
      "\n",
      "[ 0.5  0.5]\n",
      "['Burglary']\n",
      "{'Burglary': 1}\n"
     ]
    }
   ],
   "source": [
    "f = Factor(bn,'Alarm')\n",
    "print f.cpt\n",
    "print f.scope\n",
    "print f.stride\n",
    "f.sumover_var('Burglary')\n",
    "print '\\n',f.cpt\n",
    "print f.scope\n",
    "print f.stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a look at \"sumout_var\", which is essentially the opposite of \"sumover_var\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Burglary': 2, 'Alarm': 1}\n",
      "['Alarm', 'Burglary']\n",
      "{'Burglary': 2, 'Alarm': 2}\n",
      "[ 0.5295  0.4705  0.38    0.62  ]\n"
     ]
    }
   ],
   "source": [
    "f = Factor(bn,'Alarm')\n",
    "f.sumout_var('Earthquake')\n",
    "print f.stride\n",
    "print f.scope\n",
    "print f.card\n",
    "print f.cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can sum over a LIST of variables with \"sumover_var_list\". Notice how summing over every variable in the scope except for ONE variable is equivalent to summing over that ONE variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.999  0.001  0.71   0.29   0.06   0.94   0.05   0.95 ]\n",
      "['Alarm']\n",
      "{'Alarm': 1}\n",
      "[ 0.45475  0.54525]\n",
      "\n",
      "[ 0.999  0.001  0.71   0.29   0.06   0.94   0.05   0.95 ]\n",
      "['Alarm']\n",
      "{'Alarm': 1}\n",
      "[ 0.45475  0.54525]\n"
     ]
    }
   ],
   "source": [
    "f = Factor(bn,'Alarm')\n",
    "print f.cpt\n",
    "f.sumout_var_list(['Burglary','Earthquake'])\n",
    "print f.scope\n",
    "print f.stride\n",
    "print f.cpt\n",
    "\n",
    "f1 = Factor(bn,'Alarm')\n",
    "print '\\n',f1.cpt\n",
    "f1.sumover_var('Alarm')\n",
    "print f1.scope\n",
    "print f1.stride\n",
    "print f1.cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more, you can use \"maxout_var\" to take the max values over a variable in the factor. This is a fundamental operation in Max-Sum Variable Elimination for MAP inference. Notice how the variable being maxed out is removed from the scope because it is conditioned upon and thus taken as truth in a sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alarm', 'Burglary', 'Earthquake']\n",
      "[ 0.999  0.001  0.71   0.29   0.06   0.94   0.05   0.95 ]\n",
      "\n",
      "['Alarm', 'Earthquake']\n",
      "[ 0.77501  0.22499  0.05942  0.94058]\n"
     ]
    }
   ],
   "source": [
    "f = Factor(bn,'Alarm')\n",
    "print f.scope\n",
    "print f.cpt\n",
    "f.maxout_var('Burglary')\n",
    "print '\\n', f.scope\n",
    "print f.cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, you can also use \"reduce_factor\" to reduce a factor based on evidence. This is different from \"sumover_var\" because \"reduce_factor\" is not summing over anything, it is simply removing any \n",
    "        parent-child instantiations which are not consistent with\n",
    "        the evidence. Moreover, there should not be any need for\n",
    "        normalization because the CPT should already be normalized\n",
    "        over the rv-val evidence (but we do it anyways because of\n",
    "        rounding). This function is essential when user's pass in evidence to any inference query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alarm', 'Burglary', 'Earthquake']\n",
      "[ 0.999  0.001  0.71   0.29   0.06   0.94   0.05   0.95 ]\n",
      "\n",
      "['Alarm', 'Earthquake']\n",
      "[ 0.71  0.29  0.05  0.95]\n"
     ]
    }
   ],
   "source": [
    "f = Factor(bn, 'Alarm')\n",
    "print f.scope\n",
    "print f.cpt\n",
    "f.reduce_factor('Burglary','Yes')\n",
    "print '\\n', f.scope\n",
    "print f.cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another piece of functionality is the capability to convert the factor probabilities to/from log-space. This is important for MAP inference, since the sum of log-probabilities is equal the product of normal probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.999  0.001  0.71   0.29   0.06   0.94   0.05   0.95 ]\n",
      "[-0.   -6.91 -0.34 -1.24 -2.81 -0.06 -3.   -0.05]\n",
      "[ 0.999  0.001  0.71   0.29   0.06   0.94   0.05   0.95 ]\n"
     ]
    }
   ],
   "source": [
    "f = Factor(bn,'Alarm')\n",
    "print f.cpt\n",
    "f.to_log()\n",
    "print np.round(f.cpt,2)\n",
    "f.from_log()\n",
    "print f.cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we have normalization. This function does most of its work behind the scenes because it cleans up the factor probabilities after multiplication or reduction. Still, it's an important function of which users should be aware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.999  0.001  0.71   0.29   0.06   0.94   0.05   0.95 ]\n",
      "[ 20.    20.     0.71   0.29   0.94   0.94   0.05   0.15]\n",
      "[ 0.5   0.5   0.71  0.29  0.5   0.5   0.25  0.75]\n"
     ]
    }
   ],
   "source": [
    "f = Factor(bn, 'Alarm')\n",
    "print f.cpt\n",
    "f.cpt[0]=20\n",
    "f.cpt[1]=20\n",
    "f.cpt[4]=0.94\n",
    "f.cpt[7]=0.15\n",
    "print f.cpt\n",
    "f.normalize()\n",
    "print f.cpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for factor operations with pyBN. As you can see, there is a lot going on with factor operations. While these functions are the behind-the-scenes drivers of most inference queries, it is still useful for users to see how they operate. These operations have all been optimized to run incredibly fast so that inference queries can be as fast as possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
